{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfIBP2T6jCUx"
      },
      "outputs": [],
      "source": [
        "! pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkoykbZHjILp"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import drive\n",
        "from PIL import Image\n",
        "from os import path\n",
        "from tqdm import tqdm\n",
        "from transformers import ViTFeatureExtractor, ViTForImageClassification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3E3xekLMjhkq"
      },
      "outputs": [],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PRAGAkyje67"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQ5n664JjepZ"
      },
      "outputs": [],
      "source": [
        "IMG_PATH = f'/content/drive/My Drive/CLIP_Facial_Impressions/omi/images'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_9OSPDXl3V8"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ys5pUNoynAwI"
      },
      "outputs": [],
      "source": [
        "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-large-patch32-384')\n",
        "model = ViTForImageClassification.from_pretrained('google/vit-large-patch32-384').to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRgvQLoCl3HE"
      },
      "outputs": [],
      "source": [
        "first_impression_images = [path.join(IMG_PATH, f'{i}.jpg') for i in range(1,1005)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0edFpRQcmngP"
      },
      "outputs": [],
      "source": [
        "vecs = []\n",
        "\n",
        "for img in tqdm(first_impression_images):\n",
        "  image = Image.open(path.join(IMG_PATH, img))\n",
        "  inputs = feature_extractor(images=image, return_tensors=\"pt\").to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    outputs = model(**inputs,output_hidden_states=True)\n",
        "    vec = outputs.hidden_states[-1].mean(axis=1)\n",
        "    vecs.append(vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "quE1wMOTpJvC"
      },
      "outputs": [],
      "source": [
        "final_vecs = torch.stack(vecs)\n",
        "final_vecs = final_vecs.squeeze(1)\n",
        "final_vecs = final_vecs.to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXHUvxGXrdff"
      },
      "outputs": [],
      "source": [
        "np_vecs = final_vecs.numpy()\n",
        "np.save(f'/content/drive/My Drive/CLIP_Facial_Impressions/vit_vecs.npy', np_vecs)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
